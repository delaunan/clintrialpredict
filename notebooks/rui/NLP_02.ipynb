{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c54e7764",
   "metadata": {},
   "source": [
    "## Plan\n",
    "\n",
    "We will build a complete Hugging Face Fine-Tuning Pipeline for binary classification.\n",
    "\n",
    "Data Bridge: Convert your Pandas DataFrame into a Hugging Face Dataset.\n",
    "\n",
    "Tokenization: Apply the BioBERT tokenizer to the txt_criteria column (identified in your audit as the complex text source).\n",
    "\n",
    "Metrics: Define a compute_metrics function using F1-score and Precision (crucial for imbalanced data).\n",
    "\n",
    "Training: Set up TrainingArguments optimized for a quick MVP (fewer epochs, lower batch size)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bf3830",
   "metadata": {},
   "source": [
    "## The Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33bc0766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: datasets in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (4.4.1)\n",
      "Requirement already satisfied: filelock in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from datasets) (2.2.6)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruima/.pyenv/versions/clintrialpredict/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: parse error near `-m'\n",
      "zsh:1: parse error near `-m'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install torch\n",
    "!pip install datasets\n",
    "from datasets import Dataset\n",
    "from transformers import (AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade accelerate\n",
    "!{sys.executable} -m pip install --upgrade \"transformers[torch]\"\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e8b61",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5b12b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['nct_id', 'start_date_type', 'start_date', 'study_type',\n",
       "       'overall_status', 'phase', 'number_of_arms', 'why_stopped', 'target',\n",
       "       'start_year', 'phase_ordinal', 'covid_exposure', 'includes_us',\n",
       "       'is_international', 'agency_class', 'allocation', 'intervention_model',\n",
       "       'primary_purpose', 'masking', 'gender', 'healthy_volunteers', 'adult',\n",
       "       'child', 'older_adult', 'num_primary_endpoints', 'best_pathology',\n",
       "       'therapeutic_area', 'therapeutic_subgroup_name', 'competition_broad',\n",
       "       'competition_niche', 'txt_tags', 'txt_criteria'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"/home/ruima/code/delaunan/clintrialpredict/data\"\n",
    "df = pd.read_csv(os.path.join(DATA_PATH, 'project_data.csv'))\n",
    "df.columns\n",
    "#df.shape\n",
    "#df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fcc221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COMPLETED' 'TERMINATED' 'WITHDRAWN' 'SUSPENDED']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(105336, 32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['overall_status'].value_counts()\n",
    "print(df['overall_status'].unique())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c74880a",
   "metadata": {},
   "source": [
    "## Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfa04033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. SETUP & DATA PREPARATION\n",
    "# ==========================================\n",
    "# We filter for the target classes and map them to 0/1\n",
    "# 0 = Failed (Risk), 1 = Completed (Success)\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "# Filter for relevant statuses only\n",
    "target_mask = df['overall_status'].isin(['COMPLETED', 'TERMINATED',\n",
    "                                         'WITHDRAWN', 'SUSPENDED'])\n",
    "df_clean = df[target_mask].copy()\n",
    "\n",
    "# Create Binary Target: 1 if Failed, 0 if Completed\n",
    "df_clean['label'] = df_clean['overall_status'].apply(\n",
    "    lambda x: 1 if x == 'Completed' else 0\n",
    ")\n",
    "\n",
    "# Handle Missing Text (Crucial for BERT)\n",
    "df_clean['txt_criteria'] = df_clean['txt_criteria'].fillna(\"missing\")\n",
    "\n",
    "# Split Data (Stratified because of class imbalance)\n",
    "train_df, val_df = train_test_split(\n",
    "    df_clean, test_size=0.2, stratify=df_clean['label'], random_state=42\n",
    ")\n",
    "\n",
    "# Convert to Hugging Face Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_df[['txt_criteria', 'label']])\n",
    "val_dataset = Dataset.from_pandas(val_df[['txt_criteria', 'label']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85caab",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13b14e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.39.3\n",
      "  Using cached transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
      "Collecting filelock (from transformers==4.39.3)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers==4.39.3)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy>=1.17 (from transformers==4.39.3)\n",
      "  Using cached numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting packaging>=20.0 (from transformers==4.39.3)\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.39.3)\n",
      "  Using cached pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.39.3)\n",
      "  Using cached regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers==4.39.3)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.39.3)\n",
      "  Using cached tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.39.3)\n",
      "  Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.39.3)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.3)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.3)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.3)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers==4.39.3)\n",
      "  Using cached charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers==4.39.3)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.39.3)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers==4.39.3)\n",
      "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Using cached tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Using cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Using cached numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Using cached pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
      "Using cached regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)\n",
      "Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tqdm, safetensors, regex, pyyaml, packaging, numpy, idna, hf-xet, fsspec, filelock, charset_normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "\u001b[2K  Attempting uninstall: urllib3\n",
      "\u001b[2K    Found existing installation: urllib3 2.5.0\n",
      "\u001b[2K    Uninstalling urllib3-2.5.0:\n",
      "\u001b[2K      Successfully uninstalled urllib3-2.5.0\n",
      "\u001b[2K  Attempting uninstall: typing-extensions笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 0/18\u001b[0m [urllib3]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.15.018\u001b[0m [urllib3]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.15.0:笏≫煤\u001b[0m \u001b[32m 0/18\u001b[0m [urllib3]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.15.0笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 1/18\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: tqdmm笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 1/18\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Found existing installation: tqdm 4.67.1笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 1/18\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Uninstalling tqdm-4.67.1:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 1/18\u001b[0m [typing-extensions]\n",
      "\u001b[2K      Successfully uninstalled tqdm-4.67.1笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 1/18\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: safetensors笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 1/18\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Found existing installation: safetensors 0.7.0笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 1/18\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Uninstalling safetensors-0.7.0:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 1/18\u001b[0m [typing-extensions]\n",
      "\u001b[2K      Successfully uninstalled safetensors-0.7.0笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 1/18\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: regex[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 3/18\u001b[0m [safetensors]s]\n",
      "\u001b[2K    Found existing installation: regex 2025.11.3笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 3/18\u001b[0m [safetensors]\n",
      "\u001b[2K    Uninstalling regex-2025.11.3:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 3/18\u001b[0m [safetensors]\n",
      "\u001b[2K      Successfully uninstalled regex-2025.11.3笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 3/18\u001b[0m [safetensors]\n",
      "\u001b[2K  Attempting uninstall: pyyaml\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 4/18\u001b[0m [regex]s]\n",
      "\u001b[2K    Found existing installation: PyYAML 6.0.3笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 4/18\u001b[0m [regex]\n",
      "\u001b[2K    Uninstalling PyYAML-6.0.3:m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 4/18\u001b[0m [regex]\n",
      "\u001b[2K      Successfully uninstalled PyYAML-6.0.3笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 4/18\u001b[0m [regex]\n",
      "\u001b[2K  Attempting uninstall: packaging笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 4/18\u001b[0m [regex]\n",
      "\u001b[2K    Found existing installation: packaging 25.0笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 4/18\u001b[0m [regex]\n",
      "\u001b[2K    Uninstalling packaging-25.0:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 4/18\u001b[0m [regex]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 4/18\u001b[0m [regex]\n",
      "\u001b[2K  Attempting uninstall: numpym笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 6/18\u001b[0m [packaging]\n",
      "\u001b[2K    Found existing installation: numpy 2.2.6笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 6/18\u001b[0m [packaging]\n",
      "\u001b[2K    Uninstalling numpy-2.2.6:91m笊ｸ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 7/18\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.6笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 7/18\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: idna[91m笊ｸ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 7/18\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: idna 3.11笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 7/18\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling idna-3.11:m笊ｸ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 7/18\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled idna-3.11笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 7/18\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: hf-xet[91m笊ｸ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 8/18\u001b[0m [idna]\n",
      "\u001b[2K    Found existing installation: hf-xet 1.2.0笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 8/18\u001b[0m [idna]\n",
      "\u001b[2K    Uninstalling hf-xet-1.2.0:笊ｸ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 8/18\u001b[0m [idna]\n",
      "\u001b[2K      Successfully uninstalled hf-xet-1.2.0笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 8/18\u001b[0m [idna]\n",
      "\u001b[2K  Attempting uninstall: fsspec笊ｸ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 8/18\u001b[0m [idna]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.10.0笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 8/18\u001b[0m [idna]\n",
      "\u001b[2K    Uninstalling fsspec-2025.10.0:m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 8/18\u001b[0m [idna]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.10.0笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 8/18\u001b[0m [idna]\n",
      "\u001b[2K  Attempting uninstall: filelock0m\u001b[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m10/18\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: filelock 3.20.0笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m10/18\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling filelock-3.20.0:0m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m10/18\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled filelock-3.20.0笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m10/18\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: charset_normalizer90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m10/18\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: charset-normalizer 3.4.4笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m12/18\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Uninstalling charset-normalizer-3.4.4:0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m12/18\u001b[0m [charset_normalizer]\n",
      "\u001b[2K      Successfully uninstalled charset-normalizer-3.4.4笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m12/18\u001b[0m [charset_normalizer]\n",
      "\u001b[2K  Attempting uninstall: certifi[0m\u001b[91m笊ｸ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m12/18\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Found existing installation: certifi 2025.11.12笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m12/18\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Uninstalling certifi-2025.11.12:91m笊ｸ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m12/18\u001b[0m [charset_normalizer]\n",
      "\u001b[2K      Successfully uninstalled certifi-2025.11.12笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m12/18\u001b[0m [charset_normalizer]\n",
      "\u001b[2K  Attempting uninstall: requests0m\u001b[91m笊ｸ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m12/18\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Found existing installation: requests 2.32.5m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m12/18\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Uninstalling requests-2.32.5:m\u001b[91m笊ｸ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m12/18\u001b[0m [charset_normalizer]\n",
      "\u001b[2K      Successfully uninstalled requests-2.32.590m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m12/18\u001b[0m [charset_normalizer]\n",
      "\u001b[2K  Attempting uninstall: huggingface-hub\u001b[0m\u001b[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m14/18\u001b[0m [requests]lizer]\n",
      "\u001b[2K    Found existing installation: huggingface-hub 0.36.0笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m14/18\u001b[0m [requests]\n",
      "\u001b[2K    Uninstalling huggingface-hub-0.36.0:[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m14/18\u001b[0m [requests]\n",
      "\u001b[2K      Successfully uninstalled huggingface-hub-0.36.0m笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m14/18\u001b[0m [requests]\n",
      "\u001b[2K  Attempting uninstall: tokenizers笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m15/18\u001b[0m [huggingface-hub]\n",
      "\u001b[2K    Found existing installation: tokenizers 0.22.1m\u001b[90m笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m15/18\u001b[0m [huggingface-hub]\n",
      "\u001b[2K    Uninstalling tokenizers-0.22.1:笏≫煤\u001b[0m\u001b[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m15/18\u001b[0m [huggingface-hub]\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.22.1[0m\u001b[90m笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m15/18\u001b[0m [huggingface-hub]\n",
      "\u001b[2K  Attempting uninstall: transformers笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[91m笊ｸ\u001b[0m\u001b[90m笏≫煤笏≫煤\u001b[0m \u001b[32m16/18\u001b[0m [tokenizers]]\n",
      "\u001b[2K    Found existing installation: transformers 4.57.3m\u001b[90m笏≫煤笏≫煤\u001b[0m \u001b[32m16/18\u001b[0m [tokenizers]\n",
      "\u001b[2K    Uninstalling transformers-4.57.3:笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[91m笊ｸ\u001b[0m\u001b[90m笏≫煤\u001b[0m \u001b[32m17/18\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.57.3笊ｸ\u001b[0m\u001b[90m笏≫煤\u001b[0m \u001b[32m17/18\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m18/18\u001b[0m [transformers][0m [transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed certifi-2025.11.12 charset_normalizer-3.4.4 filelock-3.20.0 fsspec-2025.10.0 hf-xet-1.2.0 huggingface-hub-0.36.0 idna-3.11 numpy-2.2.6 packaging-25.0 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.7.0 tokenizers-0.15.2 tqdm-4.67.1 transformers-4.39.3 typing-extensions-4.15.0 urllib3-2.5.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install \"transformers==4.39.3\" --force-reinstall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3322d404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 84268/84268 [15:11<00:00, 92.45 examples/s]\n",
      "Map: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 21068/21068 [03:45<00:00, 93.62 examples/s] \n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# PATCH: Disable chat template loading\n",
    "# ===========================\n",
    "#from huggingface_hub import file_download\n",
    "\n",
    "# Monkey-patch the internal endpoint call that tries to fetch chat templates\n",
    "#file_download._request_with_retry = lambda *args, **kwargs: None\n",
    "\n",
    "# ===========================\n",
    "# Load BioBERT tokenizer\n",
    "# ===========================\n",
    "#from transformers import AutoTokenizer\n",
    "\n",
    "# ==========================================\n",
    "# 2. TOKENIZATION\n",
    "# ==========================================\n",
    "\n",
    "model_name = \"dmis-lab/biobert-v1.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    use_fast=False,             # <--- CRITICAL FIX\n",
    "    trust_remote_code=True,\n",
    "    revision=\"main\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"txt_criteria\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512 # BioBERT limit\n",
    "    )\n",
    "\n",
    "# Apply tokenization\n",
    "print(\"Tokenizing datasets...\")\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e7c257",
   "metadata": {},
   "source": [
    "## Metrics Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91e2ebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "# ==========================================\n",
    "# 3. METRICS DEFINITION (Forced Print)\n",
    "# ==========================================\n",
    "def compute_metrics(eval_pred):\n",
    "    # Unpack the tuple\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    # 1. Convert Logits to Probabilities\n",
    "    # Check if logits is a tuple (some models return extra data), take the first element if so\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "\n",
    "    # Convert to tensor -> softmax -> numpy\n",
    "    # We select column [:, 1] for the probability of the Positive Class (1)\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(logits), dim=-1)[:, 1].numpy()\n",
    "\n",
    "    # 2. Get Predictions (0 or 1)\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # 3. Calculate Metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='binary'\n",
    "    )\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    auc = roc_auc_score(labels, probs)\n",
    "\n",
    "    # 4. FORCE PRINT (flush=True is key here)\n",
    "    print(\"\\n\" + \"=\"*40, flush=True)\n",
    "    print(f\"沒 EVALUATION REPORT (Step/Epoch End)\", flush=True)\n",
    "    print(\"=\"*40, flush=True)\n",
    "    print(f\"  窶｢ Accuracy:   {acc:.4f}\", flush=True)\n",
    "    print(f\"  窶｢ F1 Score:   {f1:.4f}\", flush=True)\n",
    "    print(f\"  窶｢ Precision:  {precision:.4f}\", flush=True)\n",
    "    print(f\"  窶｢ Recall:     {recall:.4f}\", flush=True)\n",
    "    print(f\"  窶｢ AUC:        {auc:.4f}\", flush=True)\n",
    "    print(\"=\"*40 + \"\\n\", flush=True)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'auc': auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3240c1de",
   "metadata": {},
   "source": [
    "## Model and Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07f90cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from accelerate) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: pyyaml in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from accelerate) (2.9.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: filelock in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.10.0)\n",
      "Requirement already satisfied: requests in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.11.12)\n",
      "Requirement already satisfied: transformers[torch] in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (4.39.3)\n",
      "Collecting transformers[torch]\n",
      "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from transformers[torch]) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from transformers[torch]) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from transformers[torch]) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from transformers[torch]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from transformers[torch]) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from transformers[torch]) (2025.11.3)\n",
      "Requirement already satisfied: requests in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from transformers[torch]) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers[torch])\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from transformers[torch]) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.2 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from transformers[torch]) (2.9.1)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from transformers[torch]) (1.12.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (1.2.0)\n",
      "Requirement already satisfied: psutil in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from accelerate>=0.26.0->transformers[torch]) (7.1.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.2->transformers[torch]) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.2->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.2->transformers[torch]) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.2->transformers[torch]) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.2->transformers[torch]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.2->transformers[torch]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.2->transformers[torch]) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.2->transformers[torch]) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.2->transformers[torch]) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.2->transformers[torch]) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.2->transformers[torch]) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.2->transformers[torch]) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.2->transformers[torch]) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.2->transformers[torch]) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.2->transformers[torch]) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.2->transformers[torch]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.2->transformers[torch]) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.2->transformers[torch]) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from torch>=2.2->transformers[torch]) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.2->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from jinja2->torch>=2.2->transformers[torch]) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from requests->transformers[torch]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from requests->transformers[torch]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ruima/.pyenv/versions/3.10.6/envs/clintrialpredict/lib/python3.10/site-packages (from requests->transformers[torch]) (2025.11.12)\n",
      "Using cached transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "\u001b[2K  Attempting uninstall: tokenizers\n",
      "\u001b[2K    Found existing installation: tokenizers 0.15.2\n",
      "\u001b[2K    Uninstalling tokenizers-0.15.2:\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.15.2\n",
      "\u001b[2K  Attempting uninstall: transformers笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m0/2\u001b[0m [tokenizers]\n",
      "\u001b[2K    Found existing installation: transformers 4.39.32m0/2\u001b[0m [tokenizers]\n",
      "\u001b[2K    Uninstalling transformers-4.39.3:笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.39.3笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m2/2\u001b[0m [transformers][0m [transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed tokenizers-0.22.1 transformers-4.57.3\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install --upgrade accelerate\n",
    "!{sys.executable} -m pip install --upgrade \"transformers[torch]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60a68264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_609958/1874185466.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluation...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1324' max='1324' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1324/1324 2:37:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "沒 EVALUATION REPORT (Step/Epoch End)\n",
      "========================================\n",
      "  窶｢ Accuracy:   0.1236\n",
      "  窶｢ F1 Score:   0.0000\n",
      "  窶｢ Precision:  0.0000\n",
      "  窶｢ Recall:     0.0000\n",
      "  窶｢ AUC:        nan\n",
      "========================================\n",
      "\n",
      "eval_loss: 0.8567\n",
      "eval_model_preparation_time: 0.0086\n",
      "eval_accuracy: 0.1236\n",
      "eval_f1: 0.0000\n",
      "eval_precision: 0.0000\n",
      "eval_recall: 0.0000\n",
      "eval_auc: nan\n",
      "eval_runtime: 9454.4273\n",
      "eval_samples_per_second: 2.2400\n",
      "eval_steps_per_second: 0.1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruima/.pyenv/versions/clintrialpredict/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/ruima/.pyenv/versions/clintrialpredict/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. MODEL & TRAINING ARGUMENTS (FIXED)\n",
    "# ==========================================\n",
    "# Load Model with Classification Head\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# Define Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",          # <--- CHANGED: evaluation_strategy -> eval_strategy\n",
    "    save_strategy=\"epoch\",          # Save model at end of every epoch\n",
    "    learning_rate=2e-5,             # Standard BERT learning rate\n",
    "    per_device_train_batch_size=8,  # Keep small to avoid GPU OOM (8 or 16)\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,             # Start small for MVP (1-2 epochs)\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",     # Optimize for F1, not Accuracy\n",
    "    logging_steps=50,\n",
    "    fp16=torch.cuda.is_available(), # Use Mixed Precision if GPU available (Speedup)\n",
    "    report_to=\"none\"                # Disable WandB/MLFlow for simple local run\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Starting Evaluation...\")\n",
    "metrics = trainer.evaluate()\n",
    "\n",
    "# Print metrics\n",
    "for k, v in metrics.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0544927e",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372fb736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. EXECUTION\n",
    "# ==========================================\n",
    "# Warning: This line starts the heavy compute\n",
    "print(\"Starting Fine-Tuning...\")\n",
    "trainer.train()\n",
    "\n",
    "# Save the final model for your Streamlit app\n",
    "trainer.save_model(\"./final_biobert_risk_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clintrialpredict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
