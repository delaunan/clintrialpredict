{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23d369a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ðŸ” CLINICAL TRIAL DATA AUDIT: EMBEDDINGS INTEGRATION ===\n",
      "\n",
      "1. Loading Main Cohort: project_data.csv...\n",
      "   -> Rows: 67,363\n",
      "   -> Unique NCT_IDs: 67,363\n",
      "\n",
      "2. Loading Embeddings: embeddings_with_nctid.csv...\n",
      "   -> Rows: 105,336\n",
      "   -> Columns: 101\n",
      "\n",
      "3. Checking Embedding Integrity...\n",
      "   [âœ“] No duplicate NCT_IDs in embedding file.\n",
      "   -> Detected 100 embedding dimensions.\n",
      "   [âœ“] No NaNs in embedding vectors.\n",
      "\n",
      "4. Merge Simulation (Left Join)...\n",
      "   --------------------------------------------------\n",
      "   Total Trials in Main Cohort:    67,363\n",
      "   --------------------------------------------------\n",
      "   âœ… MATCHED (Have Embeddings):    67,363  (100.0%)\n",
      "   âš ï¸ MISSING (Will be 0-filled):        0  (0.0%)\n",
      "   --------------------------------------------------\n",
      "   â„¹ï¸  Unused Embeddings (ignored):  37,973\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DATA_PATH = '/home/delaunan/code/delaunan/clintrialpredict/data'\n",
    "MAIN_DATA_FILE = 'project_data.csv'      # Your existing processed data\n",
    "EMB_FILE = 'embeddings_with_nctid.csv'   # The new file to merge\n",
    "\n",
    "def audit_embeddings():\n",
    "    print(\"=== ðŸ” CLINICAL TRIAL DATA AUDIT: EMBEDDINGS INTEGRATION ===\\n\")\n",
    "\n",
    "    # 1. Load Paths\n",
    "    path_main = os.path.join(DATA_PATH, MAIN_DATA_FILE)\n",
    "    path_emb = os.path.join(DATA_PATH, EMB_FILE)\n",
    "\n",
    "    # 2. Load Main Data\n",
    "    if os.path.exists(path_main):\n",
    "        print(f\"1. Loading Main Cohort: {MAIN_DATA_FILE}...\")\n",
    "        df_main = pd.read_csv(path_main, usecols=['nct_id', 'overall_status', 'phase'])\n",
    "        print(f\"   -> Rows: {len(df_main):,}\")\n",
    "        print(f\"   -> Unique NCT_IDs: {df_main['nct_id'].nunique():,}\")\n",
    "    else:\n",
    "        print(f\"   [!] CRITICAL: {MAIN_DATA_FILE} not found. Please generate it first.\")\n",
    "        return\n",
    "\n",
    "    # 3. Load Embeddings\n",
    "    if os.path.exists(path_emb):\n",
    "        print(f\"\\n2. Loading Embeddings: {EMB_FILE}...\")\n",
    "        try:\n",
    "            df_emb = pd.read_csv(path_emb)\n",
    "            print(f\"   -> Rows: {len(df_emb):,}\")\n",
    "            print(f\"   -> Columns: {len(df_emb.columns)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   [!] Error reading embedding file: {e}\")\n",
    "            return\n",
    "    else:\n",
    "        print(f\"   [!] CRITICAL: {EMB_FILE} not found.\")\n",
    "        return\n",
    "\n",
    "    # 4. Check Embedding File Integrity\n",
    "    print(\"\\n3. Checking Embedding Integrity...\")\n",
    "\n",
    "    # Check for Duplicate NCT_IDs in embeddings\n",
    "    if 'nct_id' not in df_emb.columns:\n",
    "        print(\"   [!] ERROR: 'nct_id' column missing in embeddings file.\")\n",
    "        return\n",
    "\n",
    "    dupes = df_emb['nct_id'].duplicated().sum()\n",
    "    if dupes > 0:\n",
    "        print(f\"   [!] WARNING: Found {dupes} duplicate NCT_IDs in embedding file. First occurrence will be kept.\")\n",
    "    else:\n",
    "        print(\"   [âœ“] No duplicate NCT_IDs in embedding file.\")\n",
    "\n",
    "    # Check for NaNs in embedding vectors\n",
    "    emb_cols = [c for c in df_emb.columns if c != 'nct_id']\n",
    "    print(f\"   -> Detected {len(emb_cols)} embedding dimensions.\")\n",
    "\n",
    "    nans = df_emb[emb_cols].isna().sum().sum()\n",
    "    if nans > 0:\n",
    "        print(f\"   [!] WARNING: Found {nans} NaN values in embedding columns. They will be filled with 0.\")\n",
    "    else:\n",
    "        print(\"   [âœ“] No NaNs in embedding vectors.\")\n",
    "\n",
    "    # 5. MERGE SIMULATION & STATS\n",
    "    print(\"\\n4. Merge Simulation (Left Join)...\")\n",
    "\n",
    "    # Identify keys\n",
    "    main_ids = set(df_main['nct_id'])\n",
    "    emb_ids = set(df_emb['nct_id'])\n",
    "\n",
    "    # Intersection\n",
    "    common = main_ids.intersection(emb_ids)\n",
    "    missing = main_ids - emb_ids\n",
    "    unused = emb_ids - main_ids\n",
    "\n",
    "    print(f\"   --------------------------------------------------\")\n",
    "    print(f\"   Total Trials in Main Cohort:  {len(main_ids):>8,}\")\n",
    "    print(f\"   --------------------------------------------------\")\n",
    "    print(f\"   âœ… MATCHED (Have Embeddings):  {len(common):>8,}  ({len(common)/len(main_ids):.1%})\")\n",
    "    print(f\"   âš ï¸ MISSING (Will be 0-filled): {len(missing):>8,}  ({len(missing)/len(main_ids):.1%})\")\n",
    "    print(f\"   --------------------------------------------------\")\n",
    "    print(f\"   â„¹ï¸  Unused Embeddings (ignored):{len(unused):>8,}\")\n",
    "\n",
    "    # 6. Drill Down on Missing Data (If any)\n",
    "    if len(missing) > 0:\n",
    "        print(f\"\\n5. Analysis of MISSING Embeddings (The {len(missing)/len(main_ids):.1%})...\")\n",
    "        df_missing = df_main[df_main['nct_id'].isin(missing)]\n",
    "\n",
    "        print(\"   Missing by Status:\")\n",
    "        print(df_missing['overall_status'].value_counts(normalize=True).to_string(float_format=\"{:.1%}\".format))\n",
    "\n",
    "        print(\"\\n   Missing by Phase:\")\n",
    "        print(df_missing['phase'].value_counts(normalize=True).to_string(float_format=\"{:.1%}\".format))\n",
    "\n",
    "        print(\"\\n   [Interpretation]\")\n",
    "        if len(missing) < 0.1 * len(main_ids):\n",
    "            print(\"   -> Missing rate is LOW (<10%). Filling with 0.0 is safe.\")\n",
    "        else:\n",
    "            print(\"   -> [!] Missing rate is HIGH (>10%). Ensure your embedding generation covered the full date range (2000-2015).\")\n",
    "\n",
    "# Run the audit\n",
    "audit_embeddings()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clintrialpredict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
