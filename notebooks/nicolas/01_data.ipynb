{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26fc057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2be47c1e",
   "metadata": {},
   "source": [
    "Here is the **Comprehensive Data Dictionary**. It merges the **Statistical Reality** (from your audit) with the **Business Definitions & Technical Explanations** you requested.\n",
    "\n",
    "This document explains **what** the data is, **where** it comes from, **what the labels mean**, and **why** it matters for predicting trial failure.\n",
    "\n",
    "***\n",
    "\n",
    "# Clinical Trial Risk Engine: Master Data Dictionary\n",
    "\n",
    "**Dataset Name:** `project_data.csv`\n",
    "**Total Records:** 124,490\n",
    "**Scope:** Interventional Drug Trials (Phases 1, 2, 3). *Excludes Phase 0 and Phase 4.*\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Target Variable\n",
    "\n",
    "### **`target`**\n",
    "*   **Definition:** The binary classification target indicating if the trial successfully completed its protocol.\n",
    "    *   `0`: **Completed**. The trial finished normally.\n",
    "    *   `1`: **Failed**. The trial was Terminated, Withdrawn, or Suspended.\n",
    "*   **Source:** Derived from `studies.overall_status`.\n",
    "*   **Statistics:**\n",
    "    *   **Completed (0):** 81.2%\n",
    "    *   **Failed (1):** 18.8%\n",
    "*   **Relevance:** This is the variable we are training the model to predict.\n",
    "\n",
    "### **`overall_status`**\n",
    "*   **Definition:** The raw status label provided by ClinicalTrials.gov.\n",
    "*   **Source:** `studies.overall_status`\n",
    "*   **Labels:**\n",
    "    *   `COMPLETED`: The study has concluded normally; participants are no longer being examined or treated.\n",
    "    *   `TERMINATED`: The study has stopped early and will not start again. Participants are no longer being examined or treated.\n",
    "    *   `WITHDRAWN`: The study stopped early, before enrolling its first participant.\n",
    "    *   `SUSPENDED`: The study has stopped early but may start again.\n",
    "*   **Relevance:** Source of truth for the Target. **Must be dropped before training** to prevent leakage.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Operational Signals\n",
    "*Metrics describing the logistical scale, cost, and feasibility of the study.*\n",
    "\n",
    "### **`num_facilities`**\n",
    "*   **Definition:** The total count of distinct medical centers (hospitals, clinics) listed as recruiting sites.\n",
    "*   **Source:** Calculated count of rows in `facilities.txt` per `nct_id`.\n",
    "*   **Statistics:** Mean: 13.02 sites | Max: 1,745 sites.\n",
    "*   **Relevance:** Proxy for **Operational Footprint**. High facility counts imply massive coordination costs and logistical complexity, but also suggest strong financial backing (usually Phase 3).\n",
    "\n",
    "### **`num_countries`**\n",
    "*   **Definition:** The count of unique countries where the trial is active.\n",
    "*   **Source:** Calculated count of unique values in `countries.name`.\n",
    "*   **Statistics:** Mean: 2.23 countries.\n",
    "*   **Relevance:** Proxy for **Regulatory Complexity**. Multi-country trials must satisfy multiple health authorities (FDA, EMA, PMDA) simultaneously, increasing the risk of administrative delays or shutdowns.\n",
    "\n",
    "### **`phase_ordinal`**\n",
    "*   **Definition:** A numeric mapping of the trial phase to represent the progression of drug development.\n",
    "*   **Source:** Mapped from `studies.phase`.\n",
    "*   **Labels & Logic:**\n",
    "    *   `1.0` (**Phase 1**): Safety & Dosage. Small cohorts. High technical risk, low operational risk.\n",
    "    *   `1.5` (**Phase 1/Phase 2**): Adaptive design. Seamless transition from safety to efficacy.\n",
    "    *   `2.0` (**Phase 2**): Efficacy. Medium cohorts. High risk of scientific failure (drug doesn't work).\n",
    "    *   `2.5` (**Phase 2/Phase 3**): Adaptive design.\n",
    "    *   `3.0` (**Phase 3**): Confirmation. Large cohorts. High risk of operational failure (cost/recruitment) and statistical futility.\n",
    "*   **Relevance:** The single strongest predictor of trial size and cost.\n",
    "\n",
    "### **`start_year`**\n",
    "*   **Definition:** The calendar year the trial began.\n",
    "*   **Source:** Extracted from `studies.start_date`.\n",
    "*   **Statistics:** Mean: 2012.4.\n",
    "*   **Relevance:** Captures **Modernization**. Clinical trial standards have become stricter over time. \"Fail Fast\" strategies in Pharma mean newer trials might be terminated more aggressively than older ones.\n",
    "\n",
    "### **`number_of_arms`**\n",
    "*   **Definition:** The number of distinct intervention groups in the study design (e.g., Placebo, Low Dose, High Dose = 3 arms).\n",
    "*   **Source:** `studies.number_of_arms`.\n",
    "*   **Statistics:** Mean: 2.38 arms.\n",
    "*   **Relevance:** Proxy for **Protocol Complexity**. More arms require more patients and more complex supply chain management.\n",
    "\n",
    "### **`min_age` / `max_age`**\n",
    "*   **Definition:** The numeric age limits (in years) for participant eligibility.\n",
    "*   **Source:** Parsed from `eligibilities.minimum_age` and `maximum_age`.\n",
    "*   **Statistics:** `max_age` is missing in 45% of cases (implies \"No Upper Limit\").\n",
    "*   **Relevance:** Defines the **Recruitment Pool**. Extremely narrow age ranges (e.g., \"18 to 25\") make recruitment statistically difficult, increasing the risk of termination due to \"Slow Accrual.\"\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Scientific Signals (Design)\n",
    "*Technical attributes of the experimental protocol.*\n",
    "\n",
    "### **`intervention_model`**\n",
    "*   **Definition:** The general design strategy for assigning interventions.\n",
    "*   **Source:** `designs.intervention_model`.\n",
    "*   **Labels:**\n",
    "    *   `PARALLEL` (54.5%): Participants are assigned to one group (e.g., Drug OR Placebo) and remain there. Standard for Phase 3.\n",
    "    *   `SINGLE_GROUP` (30.4%): All participants receive the intervention. No control group. Common in Phase 1 or Oncology.\n",
    "    *   `CROSSOVER` (10.2%): Participants receive Treatment A, wait, then receive Treatment B. They serve as their own control.\n",
    "    *   `FACTORIAL`: Evaluates two or more interventions simultaneously (e.g., A, B, A+B, Neither). High statistical complexity.\n",
    "    *   `SEQUENTIAL`: Participants are enrolled in stages; the trial may stop early based on interim results.\n",
    "*   **Relevance:** Complex designs (Factorial, Crossover) have higher operational risks. Single Group designs are often scientifically riskier (early phase).\n",
    "\n",
    "### **`masking`**\n",
    "*   **Definition:** The level of blinding used to prevent bias.\n",
    "*   **Source:** `designs.masking`.\n",
    "*   **Labels:**\n",
    "    *   `NONE` (Open Label): Everyone knows the treatment. High bias risk, but operationally easier.\n",
    "    *   `DOUBLE`: Participant and Investigator are blinded. Standard for rigor.\n",
    "    *   `QUADRUPLE`: Participant, Investigator, Care Provider, and Outcomes Assessor are blinded. Gold standard.\n",
    "*   **Relevance:** High rigor (Quadruple Masking) requires complex supply chains (placebo matching), increasing operational risk. Open Label (None) is common in Phase 1 but less rigorous.\n",
    "\n",
    "### **`allocation`**\n",
    "*   **Definition:** The method used to assign participants to arms.\n",
    "*   **Source:** `designs.allocation`.\n",
    "*   **Labels:** `RANDOMIZED` (82%), `NON_RANDOMIZED` (18%).\n",
    "*   **Relevance:** Randomized trials are the scientific standard but require more infrastructure than non-randomized observational-style trials.\n",
    "\n",
    "### **`primary_purpose`**\n",
    "*   **Definition:** The main reason for the clinical trial.\n",
    "*   **Source:** `designs.primary_purpose`.\n",
    "*   **Labels:** `TREATMENT` (80%), `PREVENTION`, `DIAGNOSTIC`.\n",
    "*   **Relevance:** Prevention trials (vaccines) often require massive sample sizes compared to Treatment trials, altering the risk profile.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Medical Signals (Pathology)\n",
    "*Classification of the disease being studied.*\n",
    "\n",
    "### **`therapeutic_area`**\n",
    "*   **Definition:** The highest level of the medical hierarchy (Level 1).\n",
    "*   **Source:** Derived from `browse_conditions.mesh_term` mapped to MeSH Tree Codes (C01-C26).\n",
    "*   **Labels:** Oncology, Cardiovascular, Neurology, Infectious Disease, etc.\n",
    "*   **Relevance:** **Biological Risk**. Oncology trials have historically higher failure rates due to the complexity of cancer biology compared to, say, Antibiotics (Infectious).\n",
    "\n",
    "### **`therapeutic_subgroup_name`**\n",
    "*   **Definition:** The mid-level classification derived from the MeSH Tree Structure (Level 2). Groups specific diseases into families.\n",
    "*   **Source:** Derived from `mesh_terms.xml` (Tree Number slicing).\n",
    "*   **Examples:** \"Neoplasms by Site\" (groups Breast, Lung, Colon cancer), \"Metabolic Diseases\" (groups Diabetes, Thyroid).\n",
    "*   **Relevance:** Allows the model to learn risks specific to disease families (e.g., \"Neurodegenerative diseases are hard to treat\") without getting lost in thousands of specific disease names.\n",
    "\n",
    "### **`best_pathology`**\n",
    "*   **Definition:** The specific disease name derived from the trial's condition list using a medical priority logic.\n",
    "*   **Source:** `browse_conditions.mesh_term` (Smart Selection).\n",
    "*   **Relevance:** The granular disease target.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. External Environment\n",
    "*Contextual factors impacting trial success.*\n",
    "\n",
    "### **`competition_intensity`**\n",
    "*   **Definition:** A calculated index representing recruitment competition.\n",
    "*   **Calculation:** The count of *other* drug trials that started within a **3-year window** (Start Year, +1, +2), targeting the **same Therapeutic Subgroup** and the **same Phase**.\n",
    "*   **Source:** Calculated feature.\n",
    "*   **Relevance:** **Market Saturation**. High values indicate a \"crowded\" market. If 50 companies are recruiting for \"Breast Cancer Phase 3\" at the same time, finding eligible patients becomes statistically difficult, leading to \"Slow Accrual\" termination.\n",
    "\n",
    "### **`covid_exposure`**\n",
    "*   **Definition:** A binary flag indicating if the trial started immediately before or during the peak of the COVID-19 pandemic (2019-2021).\n",
    "*   **Source:** Calculated from `studies.start_date`.\n",
    "*   **Relevance:** **External Shock**. Trials in this window faced unique risks: site closures, patient dropout, and supply chain breaks.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Sponsor & Geography\n",
    "\n",
    "### **`agency_class`**\n",
    "*   **Definition:** The type of organization sponsoring the trial.\n",
    "*   **Source:** `sponsors.agency_class`.\n",
    "*   **Labels:**\n",
    "    *   `INDUSTRY` (51%): Pharmaceutical/Biotech. High funding, but strict \"Go/No-Go\" business decisions.\n",
    "    *   `OTHER` (41%): Academic/Hospitals. Often grant-funded. May run longer/slower.\n",
    "    *   `NIH/FED` (5%): Government.\n",
    "*   **Relevance:** **Financial Risk**. Industry sponsors are more likely to terminate a trial for \"Business Reasons\" (e.g., change in strategy) even if the science is okay.\n",
    "\n",
    "### **`includes_us`**\n",
    "*   **Definition:** A binary flag indicating if at least one trial site is located in the United States.\n",
    "*   **Source:** Derived from `countries.name`.\n",
    "*   **Relevance:** **Regulatory Environment**. US trials are subject to FDA oversight (strict safety monitoring) and high healthcare costs. This often correlates with higher termination rates compared to trials in developing regions.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Text Data\n",
    "*Unstructured text fields available for Natural Language Processing.*\n",
    "\n",
    "### **`official_title`**\n",
    "*   **Definition:** The scientific title of the study.\n",
    "*   **Source:** `studies.official_title`.\n",
    "*   **Relevance:** Contains technical keywords (e.g., \"Monoclonal Antibody\", \"Placebo-Controlled\") that signal complexity.\n",
    "\n",
    "### **`criteria`**\n",
    "*   **Definition:** The detailed list of Inclusion and Exclusion criteria.\n",
    "*   **Source:** `eligibilities.criteria`.\n",
    "*   **Relevance:** **The most valuable text field.** It defines the \"narrowness\" of the eligible population. Complex, restrictive criteria are a leading cause of recruitment failure.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Analysis Fields (Excluded from Training)\n",
    "*Fields that contain future information (Data Leakage) but are useful for post-hoc analysis.*\n",
    "\n",
    "### **`min_p_value`**\n",
    "*   **Definition:** The lowest P-value reported for the trial's primary outcome measures.\n",
    "*   **Source:** `outcome_analyses.p_value`.\n",
    "*   **Relevance:** Explains **Scientific Failure**. If a trial Completed but failed to prove efficacy, the P-value will be high (>0.05).\n",
    "\n",
    "### **`why_stopped`**\n",
    "*   **Definition:** The free-text reason provided by the sponsor for termination.\n",
    "*   **Source:** `studies.why_stopped`.\n",
    "*   **Relevance:** **Ground Truth for Validation**. Used to verify if the model correctly identified a high-risk trial that later stopped for \"Lack of funding\" or \"Adverse Events\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b2e72f",
   "metadata": {},
   "source": [
    "Here is the complete, modular Data Engineering Pipeline. You can copy and paste these blocks sequentially into a Jupyter Notebook or a Python script.\n",
    "\n",
    "### Block 1: Setup & Robust Configuration\n",
    "**What this does:**\n",
    "Sets up the file paths and defines the **\"Safe Load Parameters\"**. The AACT database is messy; text fields often contain the pipe character (`|`) or unescaped quotes, which breaks standard CSV readers. These parameters force Python to read everything carefully as a string first, preventing crashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a72c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/delaunan/code/delaunan/project/00_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4db2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Setup Complete. Ready to process.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. CONFIGURATION & SETUP\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "OUTPUT_FILE = 'project_data.csv'\n",
    "\n",
    "# ROBUST LOADING PARAMETERS\n",
    "AACT_LOAD_PARAMS = {\n",
    "    \"sep\": \"|\",\n",
    "    \"dtype\": str,\n",
    "    \"header\": 0,\n",
    "    \"quotechar\": '\"',\n",
    "    \"quoting\": csv.QUOTE_MINIMAL,\n",
    "    \"low_memory\": False,\n",
    "    \"on_bad_lines\": \"warn\"\n",
    "}\n",
    "\n",
    "print(\">>> Setup Complete. Ready to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c86173d",
   "metadata": {},
   "source": [
    "### Block 2: The Funnel (Loading & Filtering)\n",
    "**What this does:**\n",
    "1.  Loads the core `studies` table.\n",
    "2.  **Filters:** Keeps only **Interventional** trials (no observational).\n",
    "3.  **Filters:** Keeps only **Drug/Biologic** trials (using the `interventions` table).\n",
    "4.  **Filters:** Keeps only **Closed** trials (Completed, Terminated, Withdrawn, Suspended) so we have a definite target.\n",
    "5.  **Target Creation:** Creates the `target` column (0 = Completed, 1 = Failed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b261a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading Studies & Applying Filters...\n",
      "   - Core Cohort Size (Phases 1-3 only): 124490 trials\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 2. THE FUNNEL: LOADING & FILTERING\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\">>> Loading Studies & Applying Filters...\")\n",
    "\n",
    "# A. Load Studies\n",
    "cols_studies = [\n",
    "    'nct_id', 'overall_status', 'study_type', 'phase',\n",
    "    'start_date', 'start_date_type',\n",
    "    'number_of_arms', 'official_title', 'why_stopped'\n",
    "]\n",
    "df = pd.read_csv(os.path.join(DATA_PATH, 'studies.txt'), usecols=cols_studies, **AACT_LOAD_PARAMS)\n",
    "\n",
    "# B. Filter: Interventional Only\n",
    "df = df[df['study_type'] == 'INTERVENTIONAL'].copy()\n",
    "\n",
    "# C. Filter: Drugs Only\n",
    "df_int = pd.read_csv(os.path.join(DATA_PATH, 'interventions.txt'), usecols=['nct_id', 'intervention_type'], **AACT_LOAD_PARAMS)\n",
    "drug_ids = df_int[df_int['intervention_type'].str.upper().isin(['DRUG', 'BIOLOGICAL'])]['nct_id'].unique()\n",
    "df = df[df['nct_id'].isin(drug_ids)]\n",
    "\n",
    "# D. Filter: Closed Statuses Only\n",
    "allowed_statuses = ['COMPLETED', 'TERMINATED', 'WITHDRAWN', 'SUSPENDED']\n",
    "df = df[df['overall_status'].isin(allowed_statuses)]\n",
    "\n",
    "# E. Filter: Exclude Phase 0 and Phase 4 (Refined Scope)\n",
    "# We only want Phase 1, 1/2, 2, 2/3, 3\n",
    "excluded_phases = ['EARLY_PHASE1', 'PHASE4', 'NA']\n",
    "df = df[~df['phase'].isin(excluded_phases)]\n",
    "\n",
    "# F. Create Target & Fix Dates\n",
    "df['target'] = df['overall_status'].apply(lambda x: 0 if x == 'COMPLETED' else 1)\n",
    "df['start_date'] = pd.to_datetime(df['start_date'], errors='coerce')\n",
    "df['start_year'] = df['start_date'].dt.year\n",
    "\n",
    "print(f\"   - Core Cohort Size (Phases 1-3 only): {len(df)} trials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9029d8",
   "metadata": {},
   "source": [
    "### Block 3: Medical Hierarchy & Subgroups\n",
    "**What this does:**\n",
    "After import of an external database with hierarchy of therapeutic area + disease, <br>\n",
    "merges the `smart_pathology_lookup.csv` you the therapeutic area information not originally present in the table <br>. \n",
    "It aslos extracts the **Therapeutic Subgroup** (e.g., `C04.588`) which is critical for the crowding calculation (how many trials are recruiting patients for the same therapeutic purpose) in the next step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dd03ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Attaching Medical Hierarchy...\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 3. MEDICAL HIERARCHY & SUBGROUPS\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\">>> Attaching Medical Hierarchy...\")\n",
    "\n",
    "# A. Load Smart Lookup (Best Term per Trial)\n",
    "df_smart = pd.read_csv(os.path.join(DATA_PATH, 'smart_pathology_lookup.csv'))\n",
    "df = df.merge(df_smart, on='nct_id', how='left')\n",
    "\n",
    "# B. Fill Missing\n",
    "df['therapeutic_area'] = df['therapeutic_area'].fillna('Other/Unclassified')\n",
    "df['best_pathology'] = df['best_pathology'].fillna('Unknown')\n",
    "\n",
    "# C. Create Subgroup Code (Level 2 Hierarchy)\n",
    "# Logic: Take first 7 chars of tree number (e.g., C04.588.180 -> C04.588)\n",
    "df['therapeutic_subgroup'] = df['tree_number'].astype(str).apply(\n",
    "    lambda x: x[:7] if pd.notna(x) and len(x) >= 7 else 'Unknown'\n",
    ")\n",
    "\n",
    "# D. Map Subgroup Code to Name (Optional but good for Explainability)\n",
    "# We load the full lookup to get the name for \"C04.588\"\n",
    "df_lookup = pd.read_csv(os.path.join(DATA_PATH, 'mesh_lookup.csv'), sep='|')\n",
    "code_to_name = pd.Series(df_lookup.mesh_term.values, index=df_lookup.tree_number).to_dict()\n",
    "df['therapeutic_subgroup_name'] = df['therapeutic_subgroup'].map(code_to_name).fillna('Unknown Subgroup')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37499ac",
   "metadata": {},
   "source": [
    "\n",
    "### Block 4: Research Space Crowding (Competition Intensity)\n",
    "**What this does:**\n",
    "Calculates **`competition_intensity`**.\n",
    "*   **Logic:** It counts how many trials started in the **same 3-year window** (Start Year, +1, +2), for the **same Medical Subgroup**, and the **same Phase**.\n",
    "*   **Why:** A Phase 1 Glaucoma trial does not compete with a Phase 3 Breast Cancer trial. This metric is specific.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66e0fdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Calculating Competition Intensity (Dual Level)...\n",
      "   - Created 'competition_broad' and 'competition_niche'\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 4. DUAL-LEVEL CROWDING (Niche vs Broad) - UPDATED\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\">>> Calculating Competition Intensity (Dual Level)...\")\n",
    "\n",
    "# A. Standardize Phase for Grouping\n",
    "# Group \"Phase 1/2\" with \"Phase 2\" for competition purposes\n",
    "phase_group_map = {\n",
    "    'PHASE1': 'PHASE1', 'PHASE1/PHASE2': 'PHASE2',\n",
    "    'PHASE2': 'PHASE2', 'PHASE2/PHASE3': 'PHASE3', 'PHASE3': 'PHASE3'\n",
    "}\n",
    "df['phase_group'] = df['phase'].map(phase_group_map).fillna('UNKNOWN')\n",
    "\n",
    "# --- LEVEL 1: BROAD COMPETITION (Area + Phase) ---\n",
    "# How many trials in \"Oncology\" + \"Phase 3\" started in this window?\n",
    "grid_broad = df.groupby(['start_year', 'therapeutic_area', 'phase_group']).size().reset_index(name='count')\n",
    "dict_broad = dict(zip(zip(grid_broad['start_year'], grid_broad['therapeutic_area'], grid_broad['phase_group']), grid_broad['count']))\n",
    "\n",
    "def get_broad_crowding(row):\n",
    "    y, area, ph = row['start_year'], row['therapeutic_area'], row['phase_group']\n",
    "    if pd.isna(y): return 0\n",
    "    # Sum Year 0, +1, +2\n",
    "    return dict_broad.get((y, area, ph), 0) + dict_broad.get((y+1, area, ph), 0) + dict_broad.get((y+2, area, ph), 0)\n",
    "\n",
    "df['competition_broad'] = df.apply(get_broad_crowding, axis=1)\n",
    "\n",
    "# --- LEVEL 2: NICHE COMPETITION (Subgroup + Phase) ---\n",
    "# How many trials in \"Gastrointestinal Neoplasms\" + \"Phase 3\" started in this window?\n",
    "grid_niche = df.groupby(['start_year', 'therapeutic_subgroup', 'phase_group']).size().reset_index(name='count')\n",
    "dict_niche = dict(zip(zip(grid_niche['start_year'], grid_niche['therapeutic_subgroup'], grid_niche['phase_group']), grid_niche['count']))\n",
    "\n",
    "def get_niche_crowding(row):\n",
    "    y, sub, ph = row['start_year'], row['therapeutic_subgroup'], row['phase_group']\n",
    "    if pd.isna(y) or sub == 'Unknown': return 0\n",
    "    # Sum Year 0, +1, +2\n",
    "    return dict_niche.get((y, sub, ph), 0) + dict_niche.get((y+1, sub, ph), 0) + dict_niche.get((y+2, sub, ph), 0)\n",
    "\n",
    "df['competition_niche'] = df.apply(get_niche_crowding, axis=1)\n",
    "\n",
    "df.drop(columns=['phase_group'], inplace=True)\n",
    "print(\"   - Created 'competition_broad' and 'competition_niche'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862785a4",
   "metadata": {},
   "source": [
    "### Block 5: Protocol (Age) & Results (P-Values)\n",
    "**What this does:**\n",
    "1.  **Age:** Parses `min_age` and `max_age` into numbers (Years), age of patients to enter the clinical trial.\n",
    "2.  **Endpoints:** Gets the count of primary endpoints (complexity).Many core objectives defined for a study could mean two things: <br>\n",
    "*- intent to increase scientific evidence*, you increase the number of goals so that at least one is relevant<br>\n",
    "*- complex and potentially large study*\n",
    "3.  **P-Values:** Extracts the minimum P-value for primary outcomes in case we want <br>to use it. **(Note: for now, this is for Analysis only, not Training).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edc1c878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Extracting Age, Endpoints & P-Values...\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 5. PROTOCOL DETAILS & ANALYTICAL RESULTS\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\">>> Extracting Age, Endpoints & P-Values...\")\n",
    "\n",
    "# A. Age Parsing (From Eligibilities)\n",
    "df_elig = pd.read_csv(os.path.join(DATA_PATH, 'eligibilities.txt'),\n",
    "                      usecols=['nct_id', 'minimum_age', 'maximum_age', 'criteria'],\n",
    "                      **AACT_LOAD_PARAMS)\n",
    "\n",
    "def parse_age(val):\n",
    "    if pd.isna(val): return np.nan\n",
    "    val = str(val).lower()\n",
    "    try:\n",
    "        num = float(val.split()[0])\n",
    "        if 'month' in val: return num / 12\n",
    "        if 'week' in val: return num / 52\n",
    "        if 'day' in val: return num / 365\n",
    "        return num\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df_elig['min_age'] = df_elig['minimum_age'].apply(parse_age)\n",
    "df_elig['max_age'] = df_elig['maximum_age'].apply(parse_age)\n",
    "df = df.merge(df_elig[['nct_id', 'min_age', 'max_age', 'criteria']], on='nct_id', how='left')\n",
    "\n",
    "# B. Endpoint Counts\n",
    "df_calc = pd.read_csv(os.path.join(DATA_PATH, 'calculated_values.txt'),\n",
    "                      usecols=['nct_id', 'number_of_primary_outcomes_to_measure'],\n",
    "                      **AACT_LOAD_PARAMS)\n",
    "df = df.merge(df_calc, on='nct_id', how='left')\n",
    "df['num_primary_endpoints'] = pd.to_numeric(df['number_of_primary_outcomes_to_measure'], errors='coerce').fillna(1)\n",
    "\n",
    "# C. P-Values (Analysis Only)\n",
    "# Load Outcomes to find Primary IDs\n",
    "df_outcomes = pd.read_csv(os.path.join(DATA_PATH, 'outcomes.txt'), usecols=['id', 'nct_id', 'outcome_type'], **AACT_LOAD_PARAMS)\n",
    "prim_ids = df_outcomes[df_outcomes['outcome_type'] == 'PRIMARY']['id'].unique()\n",
    "\n",
    "# Load Analyses\n",
    "df_an = pd.read_csv(os.path.join(DATA_PATH, 'outcome_analyses.txt'), usecols=['outcome_id', 'p_value'], **AACT_LOAD_PARAMS)\n",
    "df_an = df_an[df_an['outcome_id'].isin(prim_ids)]\n",
    "df_an['p_value_num'] = pd.to_numeric(df_an['p_value'], errors='coerce')\n",
    "\n",
    "# Get Min P-Value per Trial\n",
    "min_p = df_an.groupby('outcome_id')['p_value_num'].min().reset_index()\n",
    "# Link back to NCT via outcomes table\n",
    "min_p = min_p.merge(df_outcomes[['id', 'nct_id']], left_on='outcome_id', right_on='id')\n",
    "trial_p = min_p.groupby('nct_id')['p_value_num'].min().reset_index(name='min_p_value')\n",
    "\n",
    "df = df.merge(trial_p, on='nct_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f895009",
   "metadata": {},
   "source": [
    "### Block 6: Operational Proxies, Sponsors & External Factors (covid_exposure)\n",
    "**What this does:** <br><br>\n",
    "Merges the standard operational features (Lead Sponsor, Clinical trial study design defined at the start).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "836335e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Merging Operational Features & Calculating COVID Exposure...\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 6. OPERATIONAL PROXIES, SPONSORS & EXTERNAL FACTORS - UPDATED\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\">>> Merging Operational Features & Calculating COVID Exposure...\")\n",
    "\n",
    "# A. Phase Ordinal\n",
    "phase_map = {'PHASE1': 1, 'PHASE1/PHASE2': 1.5, 'PHASE2': 2, 'PHASE2/PHASE3': 2.5, 'PHASE3': 3}\n",
    "df['phase_ordinal'] = df['phase'].map(phase_map).fillna(0)\n",
    "\n",
    "# B. COVID Exposure (The Missing Piece)\n",
    "# Logic: Trials starting just before or during the peak disruption (2019-2021)\n",
    "df['covid_exposure'] = df['start_year'].between(2019, 2021).astype(int)\n",
    "\n",
    "# C. Facilities (Raw Count)\n",
    "df_fac = pd.read_csv(os.path.join(DATA_PATH, 'facilities.txt'), usecols=['nct_id', 'id'], **AACT_LOAD_PARAMS)\n",
    "fac_counts = df_fac.groupby('nct_id')['id'].count().reset_index(name='num_facilities')\n",
    "df = df.merge(fac_counts, on='nct_id', how='left')\n",
    "df['num_facilities'] = df['num_facilities'].fillna(1).astype(int)\n",
    "\n",
    "# D. Countries\n",
    "df_countries = pd.read_csv(os.path.join(DATA_PATH, 'countries.txt'), usecols=['nct_id', 'name'], **AACT_LOAD_PARAMS)\n",
    "country_stats = df_countries.groupby('nct_id').agg(\n",
    "    num_countries=('name', 'nunique'),\n",
    "    includes_us=('name', lambda x: 1 if 'United States' in x.values else 0)\n",
    ").reset_index()\n",
    "df = df.merge(country_stats, on='nct_id', how='left')\n",
    "df['num_countries'] = df['num_countries'].fillna(1).astype(int)\n",
    "df['includes_us'] = df['includes_us'].fillna(0).astype(int)\n",
    "\n",
    "# E. Sponsors & Design\n",
    "df_sponsors = pd.read_csv(os.path.join(DATA_PATH, 'sponsors.txt'), **AACT_LOAD_PARAMS)\n",
    "df_lead = df_sponsors[df_sponsors['lead_or_collaborator'] == 'lead'][['nct_id', 'agency_class']].drop_duplicates('nct_id')\n",
    "df = df.merge(df_lead, on='nct_id', how='left')\n",
    "\n",
    "cols_des = ['nct_id', 'allocation', 'intervention_model', 'masking', 'primary_purpose']\n",
    "df_des = pd.read_csv(os.path.join(DATA_PATH, 'designs.txt'), usecols=cols_des, **AACT_LOAD_PARAMS)\n",
    "df = df.merge(df_des, on='nct_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46810d7c",
   "metadata": {},
   "source": [
    "### Block 7: Save & Health Check\n",
    "**What this does:**\n",
    "1.  Drops technical columns (`start_date` is replaced by `start_year`).\n",
    "2.  Saves the final CSV.\n",
    "3.  Prints a summary so you can verify the data quality immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "116f7f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Merging Text & Saving...\n",
      "\n",
      ">>> SUCCESS: Final Dataset saved to project_data.csv\n",
      "    Rows: 124490\n",
      "    Columns: 32\n",
      "    New Features: 'competition_intensity', 'min_age', 'max_age', 'min_p_value'\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 7. TEXT MERGE & FINAL SAVE\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\">>> Merging Text & Saving...\")\n",
    "\n",
    "# A. Text Data\n",
    "df_brief = pd.read_csv(os.path.join(DATA_PATH, 'brief_summaries.txt'), usecols=['nct_id', 'description'], **AACT_LOAD_PARAMS)\n",
    "df_brief.rename(columns={'description': 'brief_summary'}, inplace=True)\n",
    "df = df.merge(df_brief, on='nct_id', how='left')\n",
    "\n",
    "df_detail = pd.read_csv(os.path.join(DATA_PATH, 'detailed_descriptions.txt'), usecols=['nct_id', 'description'], **AACT_LOAD_PARAMS)\n",
    "df_detail.rename(columns={'description': 'detailed_description'}, inplace=True)\n",
    "df = df.merge(df_detail, on='nct_id', how='left')\n",
    "\n",
    "# B. Cleanup\n",
    "# Drop technical columns\n",
    "df.drop(columns=['start_date', 'start_date_type', 'tree_number', 'number_of_primary_outcomes_to_measure'], inplace=True, errors='ignore')\n",
    "\n",
    "# C. Save\n",
    "df.to_csv(os.path.join(DATA_PATH, OUTPUT_FILE), index=False, quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "print(f\"\\n>>> SUCCESS: Final Dataset saved to {OUTPUT_FILE}\")\n",
    "print(f\"    Rows: {len(df)}\")\n",
    "print(f\"    Columns: {len(df.columns)}\")\n",
    "print(f\"    New Features: 'competition_intensity', 'min_age', 'max_age', 'min_p_value'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e61e36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> STARTING AUDIT ON: project_data.csv...\n",
      "   - Loaded 124,490 rows.\n",
      "SUCCESS: Audit saved to audit_dataset_report.txt\n",
      "You can now open this file to verify your data quality before modeling.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# -----------------------------------------------------------------------------\n",
    "INPUT_FILE = 'project_data.csv'  # Make sure this matches your final filename\n",
    "OUTPUT_REPORT = 'audit_dataset_report.txt'\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# OBJECTIVE-BASED FEATURE GROUPS (Updated for Final Schema)\n",
    "# -----------------------------------------------------------------------------\n",
    "FEATURE_GROUPS = {\n",
    "    \"1. TARGET VARIABLE (The Goal)\": [\n",
    "        \"target\",\n",
    "        \"overall_status\"\n",
    "    ],\n",
    "\n",
    "    \"2. OPERATIONAL SIGNALS (Complexity & Feasibility)\": [\n",
    "        \"num_facilities\",       # Raw count of sites\n",
    "        \"num_countries\",        # Geographic spread\n",
    "        \"phase_ordinal\",        # Size proxy (1.0 - 3.0)\n",
    "        \"number_of_arms\",       # Logistical complexity\n",
    "        \"start_year\",           # Modernization factor\n",
    "        \"min_age\",              # Protocol restrictiveness\n",
    "        \"max_age\"               # Protocol restrictiveness\n",
    "    ],\n",
    "\n",
    "    \"3. SCIENTIFIC SIGNALS (Design & Pathology)\": [\n",
    "        \"therapeutic_area\",         # High level (Oncology)\n",
    "        \"therapeutic_subgroup_name\",# Mid level (Neoplasms by Site)\n",
    "        \"best_pathology\",           # Low level (Breast Cancer)\n",
    "        \"intervention_model\",       # Parallel/Crossover\n",
    "        \"masking\",                  # Blinded?\n",
    "        \"allocation\",               # Randomized?\n",
    "        \"primary_purpose\",          # Treatment/Prevention\n",
    "        \"num_primary_endpoints\"     # Scientific complexity\n",
    "    ],\n",
    "\n",
    "    \"4. EXTERNAL ENVIRONMENT (Competition & Context)\": [\n",
    "        \"competition_niche\",        # Direct competitors (Same Subgroup + Phase)\n",
    "        \"competition_broad\",        # Resource competitors (Same Area + Phase)\n",
    "        \"covid_exposure\"            # Pandemic impact\n",
    "    ],\n",
    "\n",
    "    \"5. SPONSOR & BIAS (Who is running it?)\": [\n",
    "        \"agency_class\",             # Industry vs Academic\n",
    "        \"includes_us\"               # Regulatory environment (FDA)\n",
    "    ],\n",
    "\n",
    "    \"6. LEAKAGE CHECKS (Do not use for Training)\": [\n",
    "        \"min_p_value\",              # Result (Should be highly correlated with target)\n",
    "        \"why_stopped\"               # Result (Text explanation of failure)\n",
    "    ],\n",
    "\n",
    "    \"7. NLP INPUTS (Text Data Quality)\": [\n",
    "        \"official_title\",\n",
    "        \"brief_summary\",\n",
    "        \"detailed_description\",\n",
    "        \"criteria\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def run_objective_audit():\n",
    "    print(f\">>> STARTING AUDIT ON: {INPUT_FILE}...\")\n",
    "\n",
    "    file_path = os.path.join(DATA_PATH, INPUT_FILE)\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"[ERROR] File not found: {file_path}\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "    print(f\"   - Loaded {len(df):,} rows.\")\n",
    "\n",
    "    with open(OUTPUT_REPORT, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"================================================================\\n\")\n",
    "        f.write(f\"FINAL DATASET AUDIT REPORT\\n\")\n",
    "        f.write(f\"File: {INPUT_FILE}\\n\")\n",
    "        f.write(f\"Rows: {len(df):,}\\n\")\n",
    "        f.write(f\"Cols: {len(df.columns)}\\n\")\n",
    "        f.write(\"================================================================\\n\\n\")\n",
    "\n",
    "        for category, columns in FEATURE_GROUPS.items():\n",
    "            f.write(f\"\\n{'='*80}\\n\")\n",
    "            f.write(f\"OBJECTIVE: {category}\\n\")\n",
    "            f.write(f\"{'='*80}\\n\")\n",
    "\n",
    "            for col in columns:\n",
    "                if col not in df.columns:\n",
    "                    f.write(f\"\\n[MISSING COLUMN] '{col}' was expected but not found.\\n\")\n",
    "                    continue\n",
    "\n",
    "                # Basic Stats\n",
    "                missing = df[col].isna().sum()\n",
    "                missing_pct = (missing / len(df)) * 100\n",
    "                dtype = df[col].dtype\n",
    "\n",
    "                f.write(f\"\\n>>> FIELD: {col} ({dtype})\\n\")\n",
    "                f.write(f\"    - Missing: {missing} ({missing_pct:.2f}%)\\n\")\n",
    "\n",
    "                # NUMERIC ANALYSIS\n",
    "                if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                    stats = df[col].describe()\n",
    "                    zeros = (df[col] == 0).sum()\n",
    "                    f.write(f\"    - Mean:    {stats['mean']:.2f} (Std: {stats['std']:.2f})\\n\")\n",
    "                    f.write(f\"    - Min/Max: {stats['min']} / {stats['max']}\\n\")\n",
    "                    f.write(f\"    - Zeros:   {zeros} ({zeros/len(df):.1%})\\n\")\n",
    "\n",
    "                    # Correlation with Target (Signal Strength Check)\n",
    "                    if col != 'target':\n",
    "                        try:\n",
    "                            corr = df[[col, 'target']].corr().iloc[0,1]\n",
    "                            f.write(f\"    - Corr w/ Target: {corr:.4f} \")\n",
    "                            if abs(corr) > 0.1: f.write(\"(STRONG SIGNAL)\")\n",
    "                            elif abs(corr) < 0.01: f.write(\"(NO SIGNAL)\")\n",
    "                            f.write(\"\\n\")\n",
    "                        except:\n",
    "                            f.write(\"    - Corr w/ Target: NaN (Constant value?)\\n\")\n",
    "\n",
    "                # CATEGORICAL ANALYSIS\n",
    "                else:\n",
    "                    unique = df[col].nunique()\n",
    "                    f.write(f\"    - Unique Labels: {unique}\\n\")\n",
    "\n",
    "                    # Show distribution (Top 10)\n",
    "                    if unique < 50:\n",
    "                        f.write(\"    - Distribution:\\n\")\n",
    "                        dist = df[col].value_counts(normalize=True).head(10) * 100\n",
    "                        for val, pct in dist.items():\n",
    "                            f.write(f\"      * {str(val)[:40].ljust(40)} : {pct:.1f}%\\n\")\n",
    "                    else:\n",
    "                        f.write(\"    - Top 5 Most Frequent:\\n\")\n",
    "                        dist = df[col].value_counts().head(5)\n",
    "                        for val, count in dist.items():\n",
    "                            f.write(f\"      * {str(val)[:40].ljust(40)} : {count}\\n\")\n",
    "\n",
    "                # TEXT ANALYSIS (Specific)\n",
    "                if col in ['official_title', 'brief_summary', 'detailed_description', 'criteria', 'why_stopped']:\n",
    "                    # Avg word count\n",
    "                    word_counts = df[col].astype(str).apply(lambda x: len(x.split()) if pd.notna(x) and x.lower() != 'nan' else 0)\n",
    "                    avg_words = word_counts.mean()\n",
    "                    empty_rows = (word_counts < 3).sum()\n",
    "                    f.write(f\"    - Text Stats: Avg {avg_words:.0f} words. {empty_rows} rows are empty/short.\\n\")\n",
    "\n",
    "    print(f\"SUCCESS: Audit saved to {OUTPUT_REPORT}\")\n",
    "    print(\"You can now open this file to verify your data quality before modeling.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_objective_audit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2280a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
