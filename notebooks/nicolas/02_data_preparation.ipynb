{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "290917fa",
   "metadata": {},
   "source": [
    "### Configuration and Path Setup\n",
    "\n",
    "**Objective:** Define the absolute path to the data directory.\n",
    "**Rationale:** Ensures the code is portable across different user environments (e.g., local machine vs. cloud).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9933c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Path configured: /home/delaunan/code/delaunan/clintrialpredict/data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the absolute path to the data directory\n",
    "# Update this string if running on a different machine\n",
    "DATA_PATH = \"/home/delaunan/code/delaunan/clintrialpredict/data\"\n",
    "\n",
    "# Verify that the directory exists\n",
    "if os.path.exists(DATA_PATH):\n",
    "    print(f\"Data Path configured: {DATA_PATH}\")\n",
    "else:\n",
    "    print(f\"Error: Path not found: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c93c7d",
   "metadata": {},
   "source": [
    "### Setup and Data Loading\n",
    "\n",
    "**Objective:** Load the dataset and enforce chronological order.\n",
    "**Rationale:** Predictive modeling for future events requires data to be sorted by time to prevent temporal leakage (using future data to predict the past)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbf62e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully: 105336 rows.\n",
      "Date Range: 2000.0 to 2024.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, TargetEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. Construct File Path\n",
    "file_path = os.path.join(DATA_PATH, 'project_data.csv')\n",
    "\n",
    "# 2. Load Data\n",
    "try:\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "    print(f\"Data Loaded Successfully: {len(df)} rows.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "\n",
    "# 3. Sort by Time\n",
    "# Essential for temporal splitting.\n",
    "if 'df' in locals():\n",
    "    df = df.sort_values(by='start_year').reset_index(drop=True)\n",
    "    print(f\"Date Range: {df['start_year'].min()} to {df['start_year'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d99b27a",
   "metadata": {},
   "source": [
    "### Temporal Split (Train/Test)\n",
    "\n",
    "**Objective:** Split the data into Training (Past) and Testing (Future) sets based on an 80/20 ratio.\n",
    "**Rationale:**\n",
    "*   **Temporal Split:** Simulates real-world conditions where the model must predict future trials based on historical data.\n",
    "*   **COVID Check:** Verifies if the training set includes data from 2019+ to ensure the model learns the `covid_exposure` signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72ae0ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Set: 2000.0 - 2019.0 (Rows: 84268)\n",
      "TEST Set:  2019.0 - 2024.0 (Rows: 21068)\n",
      "Status: Training set includes COVID-era data (2019+).\n"
     ]
    }
   ],
   "source": [
    "# 1. Define Split Point (80% Train / 20% Test)\n",
    "split_idx = int(len(df) * 0.8)\n",
    "\n",
    "# 2. Separate Features and Target\n",
    "X = df.drop(columns=['target', 'overall_status'])\n",
    "y = df['target']\n",
    "\n",
    "# 3. Perform Temporal Split\n",
    "X_train = X.iloc[:split_idx]\n",
    "X_test  = X.iloc[split_idx:]\n",
    "y_train = y.iloc[:split_idx]\n",
    "y_test  = y.iloc[split_idx:]\n",
    "\n",
    "# 4. Extract Years for Post-Hoc Analysis\n",
    "train_years = X_train['start_year'].values\n",
    "test_years  = X_test['start_year'].values\n",
    "\n",
    "# 5. Verification Report\n",
    "print(f\"TRAIN Set: {train_years.min()} - {train_years.max()} (Rows: {len(X_train)})\")\n",
    "print(f\"TEST Set:  {test_years.min()} - {test_years.max()} (Rows: {len(X_test)})\")\n",
    "\n",
    "# Check for COVID coverage in Training\n",
    "if train_years.max() >= 2019:\n",
    "    print(\"Status: Training set includes COVID-era data (2019+).\")\n",
    "else:\n",
    "    print(\"Status: Training set ends before COVID era.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5902a98f",
   "metadata": {},
   "source": [
    "### Encoding Pipeline Definition\n",
    "\n",
    "**Objective:** Define the transformation logic for each data type based on the Audit Blueprint.\n",
    "**Strategies:**\n",
    "*   **Binary:** `OneHotEncoder` (drop one column).\n",
    "*   **Nominal (<50):** `OneHotEncoder` (keep all columns).\n",
    "*   **High Cardinality (>50):** `TargetEncoder` (maps category to failure probability).\n",
    "*   **Text Tags:** `TfidfVectorizer` (top 100 keywords).\n",
    "*   **Numeric:** Dropped in this step (handled by separate scaling pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ad12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "import re\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "N_TEXT_FEATURES = 100\n",
    "\n",
    "# 1. Define Feature Groups\n",
    "CAT_BINARY = ['is_international', 'covid_exposure', 'healthy_volunteers',\n",
    "              'adult', 'child', 'older_adult', 'includes_us']\n",
    "\n",
    "CAT_NOMINAL = ['gender', 'agency_class', 'masking', 'intervention_model',\n",
    "               'primary_purpose', 'therapeutic_area', 'allocation']\n",
    "\n",
    "CAT_HIGH_CARD = ['therapeutic_subgroup_name', 'best_pathology']\n",
    "\n",
    "# --- TEXT FEATURE (DISABLED FOR BASELINE) ---\n",
    "# TEXT_TAGS = 'txt_tags'\n",
    "\n",
    "# 2. Define Stop Words (DISABLED)\n",
    "# clinical_stop_words = [\n",
    "#     'study', 'trial', 'clinical', 'phase', 'group', 'cohort', 'arm',\n",
    "#     'randomized', 'randomised', 'controlled', 'double', 'blind', 'open', 'label',\n",
    "#     'safety', 'efficacy', 'comparison', 'evaluation',\n",
    "#     'patient', 'subject', 'participant', 'volunteer'\n",
    "# ]\n",
    "# final_stop_words = list(ENGLISH_STOP_WORDS) + clinical_stop_words\n",
    "\n",
    "# 3. Define Text Cleaning Logic (DISABLED)\n",
    "# def clean_text_logic(series):\n",
    "#     s = series.fillna('').str.lower()\n",
    "#     s = s.str.replace(r'\\d+', '', regex=True)\n",
    "#     s = s.str.replace(r'(\\w{2,})ies\\b', r'\\1y', regex=True)\n",
    "#     s = s.str.replace(r'(\\w{3,})s\\b', r'\\1', regex=True)\n",
    "#     return s\n",
    "\n",
    "# 4. Define Pipelines\n",
    "pipe_bin = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    OneHotEncoder(drop='if_binary', dtype=int, handle_unknown='ignore')\n",
    ")\n",
    "\n",
    "pipe_nom = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value='UNKNOWN'),\n",
    "    OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype=int)\n",
    ")\n",
    "\n",
    "pipe_high = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value='UNKNOWN'),\n",
    "    TargetEncoder(target_type='binary', smooth=10.0, random_state=42)\n",
    ")\n",
    "\n",
    "# Text Pipeline (DISABLED)\n",
    "# pipe_txt = make_pipeline(\n",
    "#     FunctionTransformer(clean_text_logic, validate=False, feature_names_out='one-to-one'),\n",
    "#     TfidfVectorizer(max_features=N_TEXT_FEATURES, stop_words=final_stop_words)\n",
    "# )\n",
    "\n",
    "# 5. Assemble ColumnTransformer\n",
    "encoder_step = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('binary', pipe_bin, CAT_BINARY),\n",
    "        ('nominal', pipe_nom, CAT_NOMINAL),\n",
    "        ('high_card', pipe_high, CAT_HIGH_CARD),\n",
    "        # ('text', pipe_txt, TEXT_TAGS)  <-- DISABLED HERE\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    verbose_feature_names_out=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b5bfb8",
   "metadata": {},
   "source": [
    "### Execution and Verification\n",
    "\n",
    "**Objective:** Fit the pipeline on the Training set and transform both sets.\n",
    "**Output:** Returns the processed categorical matrices ready for integration with scaled numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6ba42fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Categorical Features...\n",
      "Encoded Train Shape: (84268, 70)\n",
      "Encoded Test Shape:  (21068, 70)\n",
      "Total Features: 70\n",
      "Sample Features: ['is_international_1' 'covid_exposure_1' 'healthy_volunteers_t' 'adult_t'\n",
      " 'child_t' 'older_adult_t' 'includes_us_1' 'gender_ALL' 'gender_FEMALE'\n",
      " 'gender_MALE']\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing Categorical Features...\")\n",
    "\n",
    "# 1. Fit on Train, Transform Train\n",
    "X_train_cat = encoder_step.fit_transform(X_train, y_train)\n",
    "\n",
    "# 2. Transform Test (No Fitting)\n",
    "X_test_cat = encoder_step.transform(X_test)\n",
    "\n",
    "# 3. Output Verification\n",
    "print(f\"Encoded Train Shape: {X_train_cat.shape}\")\n",
    "print(f\"Encoded Test Shape:  {X_test_cat.shape}\")\n",
    "\n",
    "# Verify Feature Names\n",
    "# This should now work because FunctionTransformer passes the names correctly\n",
    "new_features = encoder_step.get_feature_names_out()\n",
    "print(f\"Total Features: {len(new_features)}\")\n",
    "print(f\"Sample Features: {new_features[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852cbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 20 Random Rows from the Processed Training Set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_international_1</th>\n",
       "      <th>covid_exposure_1</th>\n",
       "      <th>healthy_volunteers_t</th>\n",
       "      <th>adult_t</th>\n",
       "      <th>child_t</th>\n",
       "      <th>older_adult_t</th>\n",
       "      <th>includes_us_1</th>\n",
       "      <th>gender_ALL</th>\n",
       "      <th>gender_FEMALE</th>\n",
       "      <th>gender_MALE</th>\n",
       "      <th>...</th>\n",
       "      <th>therapeutic_area_Psychiatry</th>\n",
       "      <th>therapeutic_area_Respiratory</th>\n",
       "      <th>therapeutic_area_Stomatognathic</th>\n",
       "      <th>therapeutic_area_Urology (Male)</th>\n",
       "      <th>therapeutic_area_Wounds</th>\n",
       "      <th>allocation_NON_RANDOMIZED</th>\n",
       "      <th>allocation_RANDOMIZED</th>\n",
       "      <th>allocation_UNKNOWN</th>\n",
       "      <th>therapeutic_subgroup_name</th>\n",
       "      <th>best_pathology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109728</td>\n",
       "      <td>0.131049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124587</td>\n",
       "      <td>0.110498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085898</td>\n",
       "      <td>0.078115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.115205</td>\n",
       "      <td>0.122051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168837</td>\n",
       "      <td>0.204787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124587</td>\n",
       "      <td>0.165624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198203</td>\n",
       "      <td>0.214376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250402</td>\n",
       "      <td>0.278899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261480</td>\n",
       "      <td>0.267022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188342</td>\n",
       "      <td>0.189853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203108</td>\n",
       "      <td>0.214054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250402</td>\n",
       "      <td>0.298151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126473</td>\n",
       "      <td>0.114215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.260845</td>\n",
       "      <td>0.283772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.251908</td>\n",
       "      <td>0.298925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124587</td>\n",
       "      <td>0.179288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198203</td>\n",
       "      <td>0.141489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106210</td>\n",
       "      <td>0.155095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211114</td>\n",
       "      <td>0.168481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262072</td>\n",
       "      <td>0.275229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    is_international_1  covid_exposure_1  healthy_volunteers_t  adult_t  \\\n",
       "0                  0.0               0.0                   1.0      1.0   \n",
       "1                  0.0               0.0                   0.0      1.0   \n",
       "2                  0.0               0.0                   1.0      0.0   \n",
       "3                  0.0               0.0                   1.0      1.0   \n",
       "4                  0.0               0.0                   0.0      1.0   \n",
       "5                  0.0               0.0                   1.0      1.0   \n",
       "6                  1.0               0.0                   0.0      1.0   \n",
       "7                  1.0               0.0                   0.0      1.0   \n",
       "8                  0.0               0.0                   0.0      1.0   \n",
       "9                  0.0               0.0                   1.0      1.0   \n",
       "10                 1.0               0.0                   0.0      1.0   \n",
       "11                 0.0               0.0                   0.0      1.0   \n",
       "12                 1.0               0.0                   0.0      1.0   \n",
       "13                 1.0               0.0                   0.0      1.0   \n",
       "14                 0.0               0.0                   0.0      1.0   \n",
       "15                 0.0               0.0                   0.0      1.0   \n",
       "16                 0.0               0.0                   0.0      1.0   \n",
       "17                 0.0               0.0                   0.0      1.0   \n",
       "18                 1.0               0.0                   0.0      1.0   \n",
       "19                 0.0               0.0                   0.0      1.0   \n",
       "\n",
       "    child_t  older_adult_t  includes_us_1  gender_ALL  gender_FEMALE  \\\n",
       "0       0.0            1.0            0.0         1.0            0.0   \n",
       "1       0.0            0.0            1.0         1.0            0.0   \n",
       "2       1.0            0.0            0.0         1.0            0.0   \n",
       "3       0.0            1.0            0.0         0.0            1.0   \n",
       "4       0.0            0.0            0.0         0.0            1.0   \n",
       "5       1.0            1.0            0.0         1.0            0.0   \n",
       "6       0.0            1.0            1.0         1.0            0.0   \n",
       "7       0.0            1.0            0.0         1.0            0.0   \n",
       "8       0.0            1.0            1.0         1.0            0.0   \n",
       "9       0.0            0.0            0.0         0.0            0.0   \n",
       "10      0.0            1.0            1.0         1.0            0.0   \n",
       "11      0.0            1.0            1.0         1.0            0.0   \n",
       "12      0.0            1.0            1.0         1.0            0.0   \n",
       "13      0.0            1.0            1.0         1.0            0.0   \n",
       "14      0.0            1.0            0.0         1.0            0.0   \n",
       "15      0.0            1.0            1.0         1.0            0.0   \n",
       "16      1.0            0.0            1.0         1.0            0.0   \n",
       "17      0.0            1.0            1.0         1.0            0.0   \n",
       "18      0.0            1.0            1.0         1.0            0.0   \n",
       "19      0.0            1.0            0.0         1.0            0.0   \n",
       "\n",
       "    gender_MALE  ...  therapeutic_area_Psychiatry  \\\n",
       "0           0.0  ...                          0.0   \n",
       "1           0.0  ...                          0.0   \n",
       "2           0.0  ...                          0.0   \n",
       "3           0.0  ...                          0.0   \n",
       "4           0.0  ...                          0.0   \n",
       "5           0.0  ...                          0.0   \n",
       "6           0.0  ...                          0.0   \n",
       "7           0.0  ...                          0.0   \n",
       "8           0.0  ...                          0.0   \n",
       "9           1.0  ...                          0.0   \n",
       "10          0.0  ...                          0.0   \n",
       "11          0.0  ...                          0.0   \n",
       "12          0.0  ...                          0.0   \n",
       "13          0.0  ...                          0.0   \n",
       "14          0.0  ...                          0.0   \n",
       "15          0.0  ...                          0.0   \n",
       "16          0.0  ...                          0.0   \n",
       "17          0.0  ...                          0.0   \n",
       "18          0.0  ...                          0.0   \n",
       "19          0.0  ...                          0.0   \n",
       "\n",
       "    therapeutic_area_Respiratory  therapeutic_area_Stomatognathic  \\\n",
       "0                            0.0                              0.0   \n",
       "1                            0.0                              0.0   \n",
       "2                            0.0                              0.0   \n",
       "3                            0.0                              0.0   \n",
       "4                            0.0                              0.0   \n",
       "5                            0.0                              0.0   \n",
       "6                            0.0                              0.0   \n",
       "7                            0.0                              0.0   \n",
       "8                            0.0                              0.0   \n",
       "9                            0.0                              0.0   \n",
       "10                           0.0                              0.0   \n",
       "11                           0.0                              0.0   \n",
       "12                           0.0                              0.0   \n",
       "13                           0.0                              0.0   \n",
       "14                           0.0                              0.0   \n",
       "15                           0.0                              0.0   \n",
       "16                           0.0                              0.0   \n",
       "17                           0.0                              0.0   \n",
       "18                           0.0                              0.0   \n",
       "19                           0.0                              0.0   \n",
       "\n",
       "    therapeutic_area_Urology (Male)  therapeutic_area_Wounds  \\\n",
       "0                               0.0                      0.0   \n",
       "1                               0.0                      0.0   \n",
       "2                               0.0                      0.0   \n",
       "3                               0.0                      0.0   \n",
       "4                               1.0                      0.0   \n",
       "5                               0.0                      0.0   \n",
       "6                               0.0                      0.0   \n",
       "7                               0.0                      0.0   \n",
       "8                               0.0                      0.0   \n",
       "9                               0.0                      0.0   \n",
       "10                              0.0                      0.0   \n",
       "11                              0.0                      0.0   \n",
       "12                              0.0                      0.0   \n",
       "13                              0.0                      0.0   \n",
       "14                              0.0                      0.0   \n",
       "15                              0.0                      0.0   \n",
       "16                              0.0                      0.0   \n",
       "17                              0.0                      0.0   \n",
       "18                              0.0                      0.0   \n",
       "19                              0.0                      0.0   \n",
       "\n",
       "    allocation_NON_RANDOMIZED  allocation_RANDOMIZED  allocation_UNKNOWN  \\\n",
       "0                         0.0                    1.0                 0.0   \n",
       "1                         0.0                    0.0                 1.0   \n",
       "2                         0.0                    1.0                 0.0   \n",
       "3                         0.0                    0.0                 1.0   \n",
       "4                         0.0                    1.0                 0.0   \n",
       "5                         0.0                    1.0                 0.0   \n",
       "6                         0.0                    1.0                 0.0   \n",
       "7                         0.0                    1.0                 0.0   \n",
       "8                         0.0                    1.0                 0.0   \n",
       "9                         0.0                    1.0                 0.0   \n",
       "10                        0.0                    1.0                 0.0   \n",
       "11                        0.0                    0.0                 1.0   \n",
       "12                        0.0                    1.0                 0.0   \n",
       "13                        0.0                    1.0                 0.0   \n",
       "14                        1.0                    0.0                 0.0   \n",
       "15                        0.0                    1.0                 0.0   \n",
       "16                        0.0                    1.0                 0.0   \n",
       "17                        0.0                    1.0                 0.0   \n",
       "18                        0.0                    1.0                 0.0   \n",
       "19                        1.0                    0.0                 0.0   \n",
       "\n",
       "    therapeutic_subgroup_name  best_pathology  \n",
       "0                    0.109728        0.131049  \n",
       "1                    0.124587        0.110498  \n",
       "2                    0.085898        0.078115  \n",
       "3                    0.115205        0.122051  \n",
       "4                    0.168837        0.204787  \n",
       "5                    0.124587        0.165624  \n",
       "6                    0.198203        0.214376  \n",
       "7                    0.250402        0.278899  \n",
       "8                    0.261480        0.267022  \n",
       "9                    0.188342        0.189853  \n",
       "10                   0.203108        0.214054  \n",
       "11                   0.250402        0.298151  \n",
       "12                   0.126473        0.114215  \n",
       "13                   0.260845        0.283772  \n",
       "14                   0.251908        0.298925  \n",
       "15                   0.124587        0.179288  \n",
       "16                   0.198203        0.141489  \n",
       "17                   0.106210        0.155095  \n",
       "18                   0.211114        0.168481  \n",
       "19                   0.262072        0.275229  \n",
       "\n",
       "[20 rows x 70 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Integrity Check ---\n",
      "Min Value: 0.0\n",
      "Max Value: 1.0\n",
      "If Max > 1, it means Target Encoding is working (probabilities) or TF-IDF is working (scores).\n",
      "If Max == 1, it might be only Binary/One-Hot features.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Settings\n",
    "n_samples = 20\n",
    "feature_names = encoder_step.get_feature_names_out()\n",
    "\n",
    "# 2. Pick Random Indices\n",
    "# We use a fixed seed (42) so you see the same rows every time you run this\n",
    "rng = np.random.RandomState(42)\n",
    "random_indices = rng.choice(X_train_cat.shape[0], size=n_samples, replace=False)\n",
    "\n",
    "# 3. Slice the Data\n",
    "# We grab the specific rows corresponding to the random indices\n",
    "sample_raw = X_train_cat[random_indices]\n",
    "\n",
    "# 4. Handle Sparse Matrix\n",
    "# TF-IDF often creates a \"Sparse Matrix\" to save memory.\n",
    "# We must convert it to a standard \"Dense\" array to put it in a DataFrame.\n",
    "try:\n",
    "    sample_raw = sample_raw.toarray()\n",
    "except AttributeError:\n",
    "    pass # It is already a standard array\n",
    "\n",
    "# 5. Create and Display DataFrame\n",
    "df_sample = pd.DataFrame(sample_raw, columns=feature_names)\n",
    "\n",
    "print(f\"Displaying {n_samples} Random Rows from the Processed Training Set:\")\n",
    "display(df_sample)\n",
    "\n",
    "# 6. Quick Stats Check\n",
    "print(\"\\n--- Data Integrity Check ---\")\n",
    "print(f\"Min Value: {df_sample.min().min()}\")\n",
    "print(f\"Max Value: {df_sample.max().max()}\")\n",
    "print(\"If Max > 1, it means Target Encoding is working (probabilities) or TF-IDF is working (scores).\")\n",
    "print(\"If Max == 1, it might be only Binary/One-Hot features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "473dfcf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Access the specific 'text' pipeline inside the ColumnTransformer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m text_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_transformers_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 2. Access the TfidfVectorizer (it is the last step of that pipeline)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m text_pipeline\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/clintrialpredict/lib/python3.10/site-packages/sklearn/utils/_bunch.py:42\u001b[0m, in \u001b[0;36mBunch.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_deprecated_key_to_warnings\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}):\n\u001b[1;32m     38\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deprecated_key_to_warnings[key],\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m     41\u001b[0m     )\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "# 1. Access the specific 'text' pipeline inside the ColumnTransformer\n",
    "text_pipeline = encoder_step.named_transformers_['text']\n",
    "\n",
    "# 2. Access the TfidfVectorizer (it is the last step of that pipeline)\n",
    "vectorizer = text_pipeline.steps[-1][1]\n",
    "\n",
    "# 3. Get the words\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "# 4. Print them nicely\n",
    "print(f\"--- TF-IDF VOCABULARY ({len(vocab)} words) ---\")\n",
    "print(\"These are the words your model is actually 'reading':\\n\")\n",
    "\n",
    "# Print in groups of 10 for readability\n",
    "for i in range(0, len(vocab), 10):\n",
    "    print(vocab[i:i+10])\n",
    "\n",
    "print(\"\\n------------------------------------------------\")\n",
    "print(\"Check this list. If you see words like 'dose' or 'month', add them to 'clinical_stop_words' in Block 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f91155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clintrialpredict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
