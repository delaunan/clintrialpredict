{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "800ee154",
   "metadata": {},
   "source": [
    "Here is the deep dive **exclusively** on the Text Pipeline (TF-IDF + SVD).\n",
    "\n",
    "### 1. The Logic: From \"Words\" to \"Concepts\"\n",
    "\n",
    "You are converting raw sentences into 50 mathematical \"concepts\". Here is exactly what happens in that specific branch of your pipeline:\n",
    "\n",
    "#### Step A: TF-IDF (The \"Flavor\" Profiler)\n",
    "*   **What it does:** It turns text into a giant table where columns are words (e.g., \"cancer\", \"pain\", \"vaccine\").\n",
    "*   **The Math:**\n",
    "    *   **TF (Term Frequency):** How often does \"insulin\" appear in *this* trial? (High count = important for this row).\n",
    "    *   **IDF (Inverse Document Frequency):** How rare is \"insulin\" across *all* trials?\n",
    "        *   \"Patient\" appears everywhere $\\to$ Weight = 0.01 (Ignored).\n",
    "        *   \"Insulin\" appears rarely $\\to$ Weight = 0.95 (High Signal).\n",
    "*   **Result:** A sparse matrix of **(84,268 rows × 5,000 columns)**. Most cells are zero.\n",
    "\n",
    "#### Step B: SVD (The Compressor)\n",
    "*   **What it does:** It looks at those 5,000 columns and realizes that \"insulin\", \"diabetes\", \"glucose\", and \"type 2\" almost always appear together.\n",
    "*   **The Math:** It collapses these correlated words into a single \"Topic\" (or Component).\n",
    "    *   Instead of 4 columns, you get **1 column** (let's call it `Topic_Metabolic`).\n",
    "    *   If a trial has \"insulin\" and \"glucose\", it gets a high score on `Topic_Metabolic`.\n",
    "*   **Result:** A dense matrix of **(84,268 rows × 50 columns)**.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. The Code: Visualize & Audit the Text Signals\n",
    "\n",
    "Run this code to see exactly what your SVD learned. It will show you the **Top Words** for the main topics and the **Explained Variance** (how much information was kept).\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Access the specific Text Pipeline steps\n",
    "# We dig into the pipeline to get the trained objects\n",
    "txt_pipe = pipeline.named_transformers_['txt_tags_svd']\n",
    "tfidf_step = txt_pipe.named_steps['tfidf']\n",
    "svd_step = txt_pipe.named_steps['svd']\n",
    "\n",
    "# Get the vocabulary (The 5,000 words TF-IDF kept)\n",
    "vocab = tfidf_step.get_feature_names_out()\n",
    "\n",
    "# ==========================================================\n",
    "# STAT 1: EXPLAINED VARIANCE (How much info did we keep?)\n",
    "# ==========================================================\n",
    "total_var = svd_step.explained_variance_ratio_.sum() * 100\n",
    "print(f\"\\n>>> SVD PERFORMANCE METRICS\")\n",
    "print(f\"Total Information Retained by 50 Components: {total_var:.2f}%\")\n",
    "print(\"   (Note: In text data, 10-20% is usually enough to capture the main topics. >50% is excellent.)\")\n",
    "\n",
    "# Plot the cumulative variance\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(np.cumsum(svd_step.explained_variance_ratio_), marker='.')\n",
    "plt.title('Cumulative Explained Variance by SVD Components')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Variance')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ==========================================================\n",
    "# STAT 2: DECODING THE TOPICS (What do the columns mean?)\n",
    "# ==========================================================\n",
    "print(\"\\n>>> DECODING THE TOP 6 'HIDDEN' TOPICS\")\n",
    "print(\"These are the words that drive the values in your new 'truncatedsvd' columns.\\n\")\n",
    "\n",
    "def get_top_words_for_topic(topic_idx, n_words=8):\n",
    "    # Get the row from the V matrix (components_)\n",
    "    component = svd_step.components_[topic_idx]\n",
    "    # Sort indices by the absolute weight (magnitude of contribution)\n",
    "    top_indices = np.argsort(component)[::-1][:n_words]\n",
    "    # Map indices to words\n",
    "    top_words = [(vocab[i], component[i]) for i in top_indices]\n",
    "    return top_words\n",
    "\n",
    "# Create a plot for the top 6 topics\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(6):\n",
    "    words_weights = get_top_words_for_topic(i)\n",
    "    words, weights = zip(*words_weights)\n",
    "    \n",
    "    sns.barplot(x=list(weights), y=list(words), ax=axes[i], palette='viridis')\n",
    "    axes[i].set_title(f\"SVD Component {i} (Topic {i})\")\n",
    "    axes[i].set_xlabel(\"Weight (Importance)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 3. How to Interpret the Output\n",
    "\n",
    "#### A. The Variance Plot\n",
    "*   **Curve Shape:** It should rise steeply at the beginning and then flatten out.\n",
    "*   **Meaning:** The first few components (0, 1, 2) capture the \"Big Themes\" (Cancer, Pain, Vaccines). The later components (40-50) capture tiny details.\n",
    "*   **The %:** If it says **\"Total Information Retained: 15%\"**, don't panic. Text is messy. Capturing 15-20% of the *mathematical variance* of 5,000 words often captures 90% of the *semantic meaning* needed for prediction.\n",
    "\n",
    "#### B. The Bar Charts (The \"Fingerprints\")\n",
    "This is the most important check.\n",
    "*   **Component 0:** Usually the \"Average Trial\". It might contain generic medical words like *patients, disease, treatment*.\n",
    "*   **Component 1:** Often the largest specific field. Likely **Oncology** (*tumor, solid, advanced, metastatic*).\n",
    "*   **Component 2:** Often the \"Opposite\" of Component 1. If Comp 1 was Cancer, Comp 2 might be **Cardiology** or **Pain**.\n",
    "*   **Component 3:** Might be **Infectious Disease** (*covid, vaccine, virus*).\n",
    "\n",
    "**If you see these clear clusters, your TF-IDF + SVD is working perfectly.** It has successfully taught the computer the difference between a Cancer trial and a Covid trial without you ever explicitly programming those rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dd0017",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
